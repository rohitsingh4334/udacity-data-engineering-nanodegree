{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "### Step 1: Scope the Project and Gather Data\n",
    "\n",
    "#### Scope \n",
    "For this capstone project, we need to aggregate the immigration data by city to create out 1st dimension table. Further, we have to aggregate the city temperature data w.r.t city to create city-wise temperature dimension table. For fact table, join both dimension tables on city. \n",
    "We will use spark for the etl processing.\n",
    "\n",
    "#### Describe and Gather Data \n",
    "The I94 immigration data comes from [the US National Tourism and Trade Office website](https://travel.trade.gov/research/reports/i94/historical/2016.html). It is provided in SAS7BDAT format which is a binary database storage format.\n",
    "\n",
    "**U.S. City Demographic Data (demog):** comes from OpenSoft and includes data by city, state, age, population, veteran status and race.\n",
    "- i94yr = 4 digit year\n",
    "- i94mon = numeric month\n",
    "- i94cit = 3 digit code of origin city\n",
    "- i94port = 3 character code of destination USA city\n",
    "- arrdate = arrival date in the USA\n",
    "- i94mode = 1 digit travel code\n",
    "- depdate = departure date from the USA\n",
    "- i94visa = reason for immigration\n",
    "- The temperature data set comes from Kaggle. It is in csv format.\n",
    "\n",
    "**I94 Immigration Data (sas_data):** comes from the US National Tourism and Trade Office and includes details on incoming immigrants and their ports of entry.\n",
    "\n",
    "**Airport Code Table (airport):** comes from datahub.io and includes airport codes and corresponding cities.\n",
    "\n",
    "**Temperature Data :**\n",
    "- AverageTemperature = average temperature\n",
    "- City = city name\n",
    "- Country = country name\n",
    "- Latitude= latitude\n",
    "- Longitude = longitude"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Data Engineering Capstone Project\n",
    "\n",
    "#### Project Summary\n",
    "<p>The project's goal is to build out an ETL pipeline that uses I94 immagratin data and city tempature data to create a database that is optimized for queries to analize immagration events. The database will then be used to answer questions regarding immagration behavior to location tempatures, airports details and demographics of the cities.</p>\n",
    "\n",
    "The project follows the follow steps:\n",
    "* Step 1: Scope the Project and Gather Data\n",
    "* Step 2: Explore and Assess the Data\n",
    "* Step 3: Define the Data Model\n",
    "* Step 4: Run ETL to Model the Data\n",
    "* Step 5: Complete Project Write Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Do all imports\n",
    "from pyspark.sql import SparkSession, SQLContext, GroupedData\n",
    "from pyspark.sql.functions import *\n",
    "from glob import glob\n",
    "import pandas as pd\n",
    "from etl.extract import Extract\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# create Spark Session\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.\\\n",
    "config(\"spark.jars.packages\",\"saurfang:spark-sas7bdat:2.0.0-s_2.11\").\\\n",
    "config(\"spark.sql.broadcastTimeout\", \"36000\").\\\n",
    "enableHiveSupport().getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### file paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "paths = {\n",
    "    \"us_cities_demographics\" : \"us-cities-demographics.csv\",\n",
    "    \"airport_codes\" :  \"airport-codes_csv.csv\",\n",
    "    \"sas_data\" : \"sas_data/\",\n",
    "    \"temperature_data\": '/data2/GlobalLandTemperaturesByCity.csv'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### sas files column descriptions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I94YR : 4 digit year\n",
      "I94MON : Numeric month\n",
      "I94CIT & I94RES : This format shows all the valid and invalid codes for processing\n",
      "I94PORT : This format shows all the valid and invalid codes for processing\n",
      "I94MODE : There are missing values as well as not reported (9)\n",
      "I94BIR : Age of Respondent in Years\n",
      "COUNT : Used for summary statistics\n",
      "DTADFILE : Character Date Field - Date added to I-94 Files - CIC does not use\n",
      "VISAPOST : Department of State where where Visa was issued - CIC does not use\n",
      "OCCUP : Occupation that will be performed in U.S. - CIC does not use\n",
      "ENTDEPA : Arrival Flag - admitted or paroled into the U.S. - CIC does not use\n",
      "ENTDEPD : Departure Flag - Departed, lost I-94 or is deceased - CIC does not use\n",
      "ENTDEPU : Update Flag - Either apprehended, overstayed, adjusted to perm residence - CIC does not use\n",
      "MATFLAG : Match flag - Match of arrival and departure records\n",
      "BIRYEAR : 4 digit year of birth\n",
      "DTADDTO : Character Date Field - Date to which admitted to U.S. (allowed to stay until) - CIC does not use\n",
      "GENDER : Non-immigrant sex\n",
      "INSNUM : INS number\n",
      "AIRLINE : Airline used to arrive in U.S.\n",
      "ADMNUM : Admission Number\n",
      "FLTNO : Flight number of Airline used to arrive in U.S.\n",
      "VISATYPE : Class of admission legally admitting the non-immigrant to temporarily stay in U.S.\n"
     ]
    }
   ],
   "source": [
    "SAS_Labels_Descriptions = 'I94_SAS_Labels_Descriptions.SAS'\n",
    "\n",
    "with open(SAS_Labels_Descriptions) as f:\n",
    "    lines = f.readlines()    \n",
    "\n",
    "line_comments = [line for line in lines if '/*' in line and '*/\\n' in line]\n",
    "regexp = re.compile(r'^/\\*\\s+(?P<code>.+?)\\s+-\\s+(?P<description>.+)\\s+\\*/$')\n",
    "matched_lines = [regexp.match(c) for c in line_comments]\n",
    "\n",
    "for matched_phrase in matched_lines:\n",
    "    print(matched_phrase.group(\"code\"), \":\", matched_phrase.group('description'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "extract = Extract(spark, paths)\n",
    "\n",
    "demographics = extract.get_cities_demographics()\n",
    "airport_codes = extract.get_airports_codes()\n",
    "immigration_data = extract.get_immigration()\n",
    "temperature_data = extract.get_temperature_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Print Schema of extracted data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- City: string (nullable = true)\n",
      " |-- State: string (nullable = true)\n",
      " |-- Median Age: string (nullable = true)\n",
      " |-- Male Population: string (nullable = true)\n",
      " |-- Female Population: string (nullable = true)\n",
      " |-- Total Population: string (nullable = true)\n",
      " |-- Number of Veterans: string (nullable = true)\n",
      " |-- Foreign-born: string (nullable = true)\n",
      " |-- Average Household Size: string (nullable = true)\n",
      " |-- State Code: string (nullable = true)\n",
      " |-- Race: string (nullable = true)\n",
      " |-- Count: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "demographics.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- ident: string (nullable = true)\n",
      " |-- type: string (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- elevation_ft: string (nullable = true)\n",
      " |-- continent: string (nullable = true)\n",
      " |-- iso_country: string (nullable = true)\n",
      " |-- iso_region: string (nullable = true)\n",
      " |-- municipality: string (nullable = true)\n",
      " |-- gps_code: string (nullable = true)\n",
      " |-- iata_code: string (nullable = true)\n",
      " |-- local_code: string (nullable = true)\n",
      " |-- coordinates: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "airport_codes.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- cicid: double (nullable = true)\n",
      " |-- i94yr: double (nullable = true)\n",
      " |-- i94mon: double (nullable = true)\n",
      " |-- i94cit: double (nullable = true)\n",
      " |-- i94res: double (nullable = true)\n",
      " |-- i94port: string (nullable = true)\n",
      " |-- arrdate: double (nullable = true)\n",
      " |-- i94mode: double (nullable = true)\n",
      " |-- i94addr: string (nullable = true)\n",
      " |-- depdate: double (nullable = true)\n",
      " |-- i94bir: double (nullable = true)\n",
      " |-- i94visa: double (nullable = true)\n",
      " |-- count: double (nullable = true)\n",
      " |-- dtadfile: string (nullable = true)\n",
      " |-- visapost: string (nullable = true)\n",
      " |-- occup: string (nullable = true)\n",
      " |-- entdepa: string (nullable = true)\n",
      " |-- entdepd: string (nullable = true)\n",
      " |-- entdepu: string (nullable = true)\n",
      " |-- matflag: string (nullable = true)\n",
      " |-- biryear: double (nullable = true)\n",
      " |-- dtaddto: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- insnum: string (nullable = true)\n",
      " |-- airline: string (nullable = true)\n",
      " |-- admnum: double (nullable = true)\n",
      " |-- fltno: string (nullable = true)\n",
      " |-- visatype: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "immigration_data.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- dt: string (nullable = true)\n",
      " |-- AverageTemperature: string (nullable = true)\n",
      " |-- AverageTemperatureUncertainty: string (nullable = true)\n",
      " |-- City: string (nullable = true)\n",
      " |-- Country: string (nullable = true)\n",
      " |-- Latitude: string (nullable = true)\n",
      " |-- Longitude: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "temperature_data.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 2: Explore and Assess the Data\n",
    "\n",
    "**Transformation Step**\n",
    "<p>for cleaning the datasets, we need to import data_cleaning.py from etl directory</p>\n",
    "\n",
    "**Main steps are:**\n",
    "- Clean demographics dataset, filling null values withn 0 and grouping by city and state and pivot Race in diferent columns\n",
    "- Clean airports dataset filtering only US airports and discarting anything else that is not an airport. Extract iso regions and cast as float elevation feet.\n",
    "- Clean the immigrantion dataset. Rename columns with understandable names. Put correct formats in dates and select only important columns\n",
    "- Filtered the missing values from the temperature data and accept rows of United States."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "from etl.data_cleaning import Cleaner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "demographics = Cleaner.get_cities_demographics(demographics)\n",
    "airport_codes = Cleaner.get_airports(airport_codes)\n",
    "immigration_data = Cleaner.get_immigration(immigration_data)\n",
    "temperature_data = Cleaner.get_temperature(temperature_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Top 5 rows of extract data after cleaning step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+--------------+----------+---------------+-----------------+----------------+------------------+------------+----------------------+----------+---------------------------------+-----+-------------------------+------------------+------+\n",
      "|         City|         State|Median Age|Male Population|Female Population|Total Population|Number of Veterans|Foreign-born|Average Household Size|State Code|American Indian and Alaska Native|Asian|Black or African-American|Hispanic or Latino| White|\n",
      "+-------------+--------------+----------+---------------+-----------------+----------------+------------------+------------+----------------------+----------+---------------------------------+-----+-------------------------+------------------+------+\n",
      "|       Skokie|      Illinois|      43.4|          31382|            33437|           64819|              1066|       27424|                  2.78|        IL|                                0|20272|                     4937|              6590| 40642|\n",
      "|    Charlotte|North Carolina|      34.3|         396646|           430475|          827121|             36046|      128897|                  2.52|        NC|                             8746|55399|                   301568|            113731|446795|\n",
      "|   Manchester| New Hampshire|      37.3|          54845|            55378|          110223|              5473|       14506|                   2.4|        NH|                              558| 4304|                     6896|             11962|100108|\n",
      "|        Chico|    California|      29.9|          46168|            44168|           90336|              4519|        8425|                   2.5|        CA|                             2766| 6101|                     3164|             15578| 80467|\n",
      "|Silver Spring|      Maryland|      33.8|          40601|            41862|           82463|              1562|       30908|                   2.6|        MD|                             1084| 8841|                    21330|             25924| 37756|\n",
      "+-------------+--------------+----------+---------------+-----------------+----------------+------------------+------------+----------------------+----------+---------------------------------+-----+-------------------------+------------------+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "demographics.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-------------+--------------------+------------+---------+-----------+----------+------------+--------+---------+----------+--------------------+\n",
      "|ident|         type|                name|elevation_ft|continent|iso_country|iso_region|municipality|gps_code|iata_code|local_code|         coordinates|\n",
      "+-----+-------------+--------------------+------------+---------+-----------+----------+------------+--------+---------+----------+--------------------+\n",
      "| 00AA|small_airport|Aero B Ranch Airport|      3435.0|       NA|         US|        KS|       Leoti|    00AA|     null|      00AA|-101.473911, 38.7...|\n",
      "| 00AK|small_airport|        Lowell Field|       450.0|       NA|         US|        AK|Anchor Point|    00AK|     null|      00AK|-151.695999146, 5...|\n",
      "| 00AL|small_airport|        Epps Airpark|       820.0|       NA|         US|        AL|     Harvest|    00AL|     null|      00AL|-86.7703018188476...|\n",
      "| 00AS|small_airport|      Fulton Airport|      1100.0|       NA|         US|        OK|        Alex|    00AS|     null|      00AS|-97.8180194, 34.9...|\n",
      "| 00AZ|small_airport|      Cordes Airport|      3810.0|       NA|         US|        AZ|      Cordes|    00AZ|     null|      00AZ|-112.165000915527...|\n",
      "+-----+-------------+--------------------+------------+---------+-----------+----------+------------+--------+---------+----------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "airport_codes.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------+---------+--------+-------+--------+------+-------+--------------+-----+--------+--------+--------+------------------+---------------+----+-----+---------+---+-------+------------+--------------+\n",
      "| cic_id|cod_port|cod_state|visapost|matflag| dtaddto|gender|airline|        admnum|fltno|visatype|cod_visa|cod_mode|cod_country_origin|cod_country_cit|year|month|bird_year|age|counter|arrival_date|departure_date|\n",
      "+-------+--------+---------+--------+-------+--------+------+-------+--------------+-----+--------+--------+--------+------------------+---------------+----+-----+---------+---+-------+------------+--------------+\n",
      "|5748517|     LOS|       CA|     SYD|      M|10292016|     F|     QF|9.495387003E10|00011|      B1|       1|       1|               438|            245|2016|    4|     1976| 40|      1|  2016-04-30|    2016-05-08|\n",
      "|5748518|     LOS|       NV|     SYD|      M|10292016|     F|     VA|9.495562283E10|00007|      B1|       1|       1|               438|            245|2016|    4|     1984| 32|      1|  2016-04-30|    2016-05-17|\n",
      "|5748519|     LOS|       WA|     SYD|      M|10292016|     M|     DL|9.495640653E10|00040|      B1|       1|       1|               438|            245|2016|    4|     1987| 29|      1|  2016-04-30|    2016-05-08|\n",
      "|5748520|     LOS|       WA|     SYD|      M|10292016|     F|     DL|9.495645143E10|00040|      B1|       1|       1|               438|            245|2016|    4|     1987| 29|      1|  2016-04-30|    2016-05-14|\n",
      "|5748521|     LOS|       WA|     SYD|      M|10292016|     M|     DL|9.495638813E10|00040|      B1|       1|       1|               438|            245|2016|    4|     1988| 28|      1|  2016-04-30|    2016-05-14|\n",
      "+-------+--------+---------+--------+-------+--------+------+-------+--------------+-----+--------+--------+--------+------------------+---------------+----+-----+---------+---+-------+------------+--------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "immigration_data.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------------+-----------------------------+----------------+-------------+--------+---------+\n",
      "|        dt|AverageTemperature|AverageTemperatureUncertainty|            City|      Country|Latitude|Longitude|\n",
      "+----------+------------------+-----------------------------+----------------+-------------+--------+---------+\n",
      "|1743-11-01|             3.264|                        1.665|       Allentown|United States|  40.99N|   74.56W|\n",
      "|1820-01-01|-5.303999999999999|                        2.795|          Pueblo|United States|  37.78N|  103.73W|\n",
      "|1828-01-01|            -1.977|                        2.551|         Seattle|United States|  47.42N|  121.97W|\n",
      "|1849-01-01|            13.116|           2.5860000000000003|    Garden Grove|United States|  32.95N|  117.77W|\n",
      "|1849-01-01|            13.116|           2.5860000000000003|Huntington Beach|United States|  32.95N|  117.77W|\n",
      "+----------+------------------+-----------------------------+----------------+-------------+--------+---------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "temperature_data.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 3: Define the Data Model\n",
    "**3.1 Conceptual Data Model**\n",
    "Map out the conceptual data model and explain why you chose that model\n",
    "\n",
    "**Star Schema**\n",
    "**Dimension Tables:**\n",
    "\n",
    "- **demographics_dim**\n",
    "  - State, **state_code**, Total_Population, Male_Population, Female_Population, American_Indian_and_Alaska_Native, Asian, Black_or_African-American, Hispanic_or_Latino, White, Male_Population_Ratio, Female_Population_Ratio, American_Indian_and_Alaska_Native_Ratio, Asian_Ratio, Black_or_African-American_Ratio, Hispanic_or_Latino_Ratio, White_Ratio.\n",
    "- **airports_dim**\n",
    "  - ident, type, name, elevation_ft, continent, iso_country, iso_region, municipality, gps_code, iata_code, **local_code**, coordinates.\n",
    "\n",
    "- **temperature_dim**\n",
    "    - dt, AverageTemperature, AverageTemperatureUncertainty, City, Country, Latitude, Longitude, **i94port**\n",
    "\n",
    "**Fact Table:**\n",
    "\n",
    "- **immigration_fact**\n",
    "    - **cic_id, cod_port, cod_state**, visapost, matflag, dtaddto, gender, airline, admnum, fltno, visatype, cod_visa, cod_mode, cod_country_origin, cod_country_cit, year, month, bird_year, age, counter, arrival_date, departure_date, arrival_year, arrival_month, arrival_day.\n",
    "\n",
    "**3.2 Mapping Out Data Pipelines**\n",
    "\n",
    "**There are two steps:**\n",
    "\n",
    "- **Transform data**\n",
    "  - Transform demographics dataset grouping by state an calculate all the totals and ratios for every race in every state.\n",
    "  - Transform immigration dataset on order to get arrival date in different columns (year, month, day) for partitioning the dataset.\n",
    "\n",
    "- **Generate Model (Star Schema):**\n",
    "\n",
    "  - Create all dimensions in parquet.\n",
    "  - Create fact table in parquet particioned by year, month, day of th arrival date.\n",
    "  - Insert in fact table only items with dimension keys right. For integrity and consistency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "from etl.transform import Transformer\n",
    "\n",
    "demographics = Transformer.demographics(demographics)\n",
    "immigration_data = Transformer.immigrants(immigration_data)\n",
    "temperature_data = Transformer.temperatue(temperature_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Top 5 rows of extract data after transformation step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------+----------------+---------------+-----------------+---------------------------------+------+-------------------------+------------------+-------+---------------------+-----------------------+---------------------------------------+-----------+-------------------------------+------------------------+-----------+\n",
      "|State_code|         State|Total_Population|Male_Population|Female_Population|American_Indian_and_Alaska_Native| Asian|Black_or_African-American|Hispanic_or_Latino|  White|Male_Population_Ratio|Female_Population_Ratio|American_Indian_and_Alaska_Native_Ratio|Asian_Ratio|Black_or_African-American_Ratio|Hispanic_or_Latino_Ratio|White_Ratio|\n",
      "+----------+--------------+----------------+---------------+-----------------+---------------------------------+------+-------------------------+------------------+-------+---------------------+-----------------------+---------------------------------------+-----------+-------------------------------+------------------------+-----------+\n",
      "|        MT|       Montana|        181294.0|        87707.0|          93587.0|                             9684|  4165|                     3349|             10000| 169026|                 0.48|                   0.52|                                   0.05|       0.02|                           0.02|                    0.06|       0.93|\n",
      "|        NC|North Carolina|       3060199.0|      1466105.0|        1594094.0|                            35209|178740|                  1029446|            354409|1790136|                 0.48|                   0.52|                                   0.01|       0.06|                           0.34|                    0.12|       0.58|\n",
      "|        MD|      Maryland|       1312129.0|       627951.0|         684178.0|                            16155|128839|                   573768|            138644| 594522|                 0.48|                   0.52|                                   0.01|        0.1|                           0.44|                    0.11|       0.45|\n",
      "|        CO|      Colorado|       2935669.0|      1454619.0|        1481050.0|                            62613|148790|                   208043|            703722|2463916|                  0.5|                    0.5|                                   0.02|       0.05|                           0.07|                    0.24|       0.84|\n",
      "|        CT|   Connecticut|        885581.0|       432157.0|         453424.0|                            10729| 48311|                   231822|            309992| 505674|                 0.49|                   0.51|                                   0.01|       0.05|                           0.26|                    0.35|       0.57|\n",
      "+----------+--------------+----------------+---------------+-----------------+---------------------------------+------+-------------------------+------------------+-------+---------------------+-----------------------+---------------------------------------+-----------+-------------------------------+------------------------+-----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "demographics.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------+---------+--------+-------+--------+------+-------+--------------+-----+--------+--------+--------+------------------+---------------+----+-----+---------+---+-------+------------+--------------+------------+-------------+-----------+\n",
      "| cic_id|cod_port|cod_state|visapost|matflag| dtaddto|gender|airline|        admnum|fltno|visatype|cod_visa|cod_mode|cod_country_origin|cod_country_cit|year|month|bird_year|age|counter|arrival_date|departure_date|arrival_year|arrival_month|arrival_day|\n",
      "+-------+--------+---------+--------+-------+--------+------+-------+--------------+-----+--------+--------+--------+------------------+---------------+----+-----+---------+---+-------+------------+--------------+------------+-------------+-----------+\n",
      "|5748517|     LOS|       CA|     SYD|      M|10292016|     F|     QF|9.495387003E10|00011|      B1|       1|       1|               438|            245|2016|    4|     1976| 40|      1|  2016-04-30|    2016-05-08|        2016|           04|         30|\n",
      "|5748518|     LOS|       NV|     SYD|      M|10292016|     F|     VA|9.495562283E10|00007|      B1|       1|       1|               438|            245|2016|    4|     1984| 32|      1|  2016-04-30|    2016-05-17|        2016|           04|         30|\n",
      "|5748519|     LOS|       WA|     SYD|      M|10292016|     M|     DL|9.495640653E10|00040|      B1|       1|       1|               438|            245|2016|    4|     1987| 29|      1|  2016-04-30|    2016-05-08|        2016|           04|         30|\n",
      "|5748520|     LOS|       WA|     SYD|      M|10292016|     F|     DL|9.495645143E10|00040|      B1|       1|       1|               438|            245|2016|    4|     1987| 29|      1|  2016-04-30|    2016-05-14|        2016|           04|         30|\n",
      "|5748521|     LOS|       WA|     SYD|      M|10292016|     M|     DL|9.495638813E10|00040|      B1|       1|       1|               438|            245|2016|    4|     1988| 28|      1|  2016-04-30|    2016-05-14|        2016|           04|         30|\n",
      "+-------+--------+---------+--------+-------+--------+------+-------+--------------+-----+--------+--------+--------+------------------+---------------+----+-----+---------+---+-------+------------+--------------+------------+-------------+-----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "immigration_data.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------------+-----------------------------+-------+-------------+--------+---------+--------+\n",
      "|        dt|AverageTemperature|AverageTemperatureUncertainty|   City|      Country|Latitude|Longitude|cod_port|\n",
      "+----------+------------------+-----------------------------+-------+-------------+--------+---------+--------+\n",
      "|1828-01-01|            -1.977|                        2.551|Seattle|United States|  47.42N|  121.97W|     SEA|\n",
      "|1849-01-01| 7.399999999999999|                        2.699|Ontario|United States|  34.56N|  116.76W|     ONT|\n",
      "|1821-11-01|             2.322|                        2.375|Spokane|United States|  47.42N|  117.24W|     SPO|\n",
      "|1835-01-01|             9.833|                        2.182|Nogales|United States|  31.35N|  111.20W|     NOG|\n",
      "|1743-11-01| 8.129999999999999|                        2.245|Atlanta|United States|  34.56N|   83.68W|     ATL|\n",
      "+----------+------------------+-----------------------------+-------+-------------+--------+---------+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "temperature_data.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 4: Run Pipelines to Model the Data \n",
    "#### 4.1 Create the data model\n",
    "Build the data pipelines to create the data model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "destination_paths = {\n",
    "    'demographics': './output/dimensions/demographics.parquet',\n",
    "    'airports': './output/dimensions/airports.parquet',\n",
    "    'temperature': './output/dimensions/temperature.parquet',\n",
    "    'facts': './output/fact/immigrations_fact.parquet'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "from etl.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "writing demographics parquet....\n",
      "writing airports parquet....\n",
      "writing temperature parquet....\n",
      "writing facts parquet....\n"
     ]
    }
   ],
   "source": [
    "model = Model(spark, destination_paths)\n",
    "\n",
    "model.modelize(immigration_data, demographics, airport_codes, temperature_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 4.2 Data Quality Checks\n",
    "Explain the data quality checks you'll perform to ensure the pipeline ran as expected. These could include:\n",
    " * Integrity constraints on the relational database (e.g., unique key, data type, etc.)\n",
    " * Unit tests for the scripts to ensure they are doing the right thing\n",
    " * Source/Count checks to ensure completeness\n",
    " \n",
    "Run Quality Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "from etl.quality_check import QualityCheck"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "checker = QualityCheck(spark, destination_paths)\n",
    "immigration_fact = checker.get_facts()\n",
    "dim_demographics, dim_airports, dim_temperature = checker.get_dimensions()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### validate that tables are not empty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checker.row_count_check(dim_demographics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checker.row_count_check(dim_airports)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checker.row_count_check(dim_temperature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checker.row_count_check(immigration_fact)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### check integrity and consistency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checker.integrity_checker(immigration_fact, dim_demographics, dim_airports, dim_temperature)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 4.3 Data dictionary \n",
    "Create a data dictionary for your data model. For each field, provide a brief description of what the data is and where it came from. You can include the data dictionary in the notebook or in a separate file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- State_code: string (nullable = true)\n",
      " |-- State: string (nullable = true)\n",
      " |-- Total_Population: double (nullable = true)\n",
      " |-- Male_Population: double (nullable = true)\n",
      " |-- Female_Population: double (nullable = true)\n",
      " |-- American_Indian_and_Alaska_Native: long (nullable = true)\n",
      " |-- Asian: long (nullable = true)\n",
      " |-- Black_or_African-American: long (nullable = true)\n",
      " |-- Hispanic_or_Latino: long (nullable = true)\n",
      " |-- White: long (nullable = true)\n",
      " |-- Male_Population_Ratio: double (nullable = true)\n",
      " |-- Female_Population_Ratio: double (nullable = true)\n",
      " |-- American_Indian_and_Alaska_Native_Ratio: double (nullable = true)\n",
      " |-- Asian_Ratio: double (nullable = true)\n",
      " |-- Black_or_African-American_Ratio: double (nullable = true)\n",
      " |-- Hispanic_or_Latino_Ratio: double (nullable = true)\n",
      " |-- White_Ratio: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dim_demographics.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- ident: string (nullable = true)\n",
      " |-- type: string (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- elevation_ft: float (nullable = true)\n",
      " |-- continent: string (nullable = true)\n",
      " |-- iso_country: string (nullable = true)\n",
      " |-- iso_region: string (nullable = true)\n",
      " |-- municipality: string (nullable = true)\n",
      " |-- gps_code: string (nullable = true)\n",
      " |-- iata_code: string (nullable = true)\n",
      " |-- local_code: string (nullable = true)\n",
      " |-- coordinates: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dim_airports.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- dt: string (nullable = true)\n",
      " |-- AverageTemperature: string (nullable = true)\n",
      " |-- AverageTemperatureUncertainty: string (nullable = true)\n",
      " |-- City: string (nullable = true)\n",
      " |-- Country: string (nullable = true)\n",
      " |-- Latitude: string (nullable = true)\n",
      " |-- Longitude: string (nullable = true)\n",
      " |-- cod_port: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dim_temperature.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- cic_id: integer (nullable = true)\n",
      " |-- cod_port: string (nullable = true)\n",
      " |-- cod_state: string (nullable = true)\n",
      " |-- visapost: string (nullable = true)\n",
      " |-- matflag: string (nullable = true)\n",
      " |-- dtaddto: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- airline: string (nullable = true)\n",
      " |-- admnum: double (nullable = true)\n",
      " |-- fltno: string (nullable = true)\n",
      " |-- visatype: string (nullable = true)\n",
      " |-- cod_visa: integer (nullable = true)\n",
      " |-- cod_mode: integer (nullable = true)\n",
      " |-- cod_country_origin: integer (nullable = true)\n",
      " |-- cod_country_cit: integer (nullable = true)\n",
      " |-- year: integer (nullable = true)\n",
      " |-- month: integer (nullable = true)\n",
      " |-- bird_year: integer (nullable = true)\n",
      " |-- age: integer (nullable = true)\n",
      " |-- counter: integer (nullable = true)\n",
      " |-- arrival_date: date (nullable = true)\n",
      " |-- departure_date: date (nullable = true)\n",
      " |-- arrival_year: integer (nullable = true)\n",
      " |-- arrival_month: integer (nullable = true)\n",
      " |-- arrival_day: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "immigration_fact.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Step 5: Complete Project Write Up\n",
    "* Clearly state the rationale for the choice of tools and technologies for the project.\n",
    "* Propose how often the data should be updated and why.\n",
    "* Write a description of how you would approach the problem differently under the following scenarios:\n",
    " * The data was increased by 100x.\n",
    " * The data populates a dashboard that must be updated on a daily basis by 7am every day.\n",
    " * The database needed to be accessed by 100+ people."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "1. For a capstone project I used Apache Spark to do all the processing data and create the data model (Start Schema). I choose Spark, because Spark can scale a lot of data and the library spark.sql has many tools to transform data. The data persisted in parquet files can scale to terabytes data with best practices.\n",
    "\n",
    "2. The data should be updated every day. We can use Apache Airflow to ingest every day (arrival date) because fact table are partitioned bay arrival date.\n",
    "\n",
    "Under the following scenarios, I would approach the problem differently:\n",
    "\n",
    "If the data was increased by 100x, no problem --> functional programming in spark makes to handle large amount of data.\n",
    "\n",
    "To update on a daily basis I would use Apache Airflow to create a schedule to update all the data,\n",
    "\n",
    "If the data needs to be accessed by 100+ people, we can store data in the S3 and further can be access by AWS Redshift/ Spark SQL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}